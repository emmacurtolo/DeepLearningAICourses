{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77b3a9",
   "metadata": {},
   "source": [
    "# Document Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65ad6c",
   "metadata": {},
   "source": [
    "We just went over how to load documents into a standard format. \n",
    "\n",
    "Now, we're going to talk about how to split them up into smaller chunks. \n",
    "\n",
    "This may sound really easy, but there's a lot of subtleties here that make a big impact down the line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c638d",
   "metadata": {},
   "source": [
    "![Split](immagini/14_splitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f5eb8",
   "metadata": {},
   "source": [
    "__Document splitting__ happens after you load your data into the document format. \n",
    "\n",
    "But before, it goes into the __vector store__, and this may seem really simple. You can just split the chunks according to the lengths of each character or something like that. \n",
    "\n",
    "But as an __example__ of why this is both trickier and very important down the line, let's take a look at this example here. \n",
    "\n",
    "We've got a sentence about the Toyota Camry and some specifications. And if we did a simple splitting, we could __end up with part of the sentence in one chunk, and the other part of the sentence in another chunk__. And then, when we're trying to answer a question down the line about what are the specifications on the Camry, __we actually don't have the right information in either chunk__, and so it's split apart. And so, we __wouldn't be able to answer this question correctly__. \n",
    "\n",
    "So, there's a lot of nuance and importance in __HOW YOU SPLIT THE CHUNKS__ so that you get __semantically relevant chunks together__.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855896cb",
   "metadata": {},
   "source": [
    "![Split](immagini/15_splitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74712755",
   "metadata": {},
   "source": [
    "The basis of all the text splitters in Lang Chain involves:\n",
    "- splitting on chunks in some chunk size with some chunk overlap. \n",
    "And so, we have a little diagram here below to show what that looks like.\n",
    "\n",
    "So, the __CHUNK SIZE__ corresponds to the size of a chunk, and the size of the chunk can be measured in a few different ways. And we'll talk about a few of those in the lesson. And so, we allow passing in a length function to measure the size of the chunk. This is often characters or tokens.  \n",
    "\n",
    "A __CHUNK OVERLAP__ is generally kept as a little overlap between two chunks, like a sliding window as we move from one to the other. And this allows for the same piece of context to be at the end of one chunk and at the start of the other and helps create some notion of consistency. \n",
    "\n",
    "The __TEXT SPLITTERS__ in Lang Chain all have a __create__ documents and a __split__ documents method. \n",
    "This involves the same logic under the hood, it just exposes a slightly different interface, \n",
    "- one that takes in a list of text and \n",
    "- another that takes in a list of documents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3636b",
   "metadata": {},
   "source": [
    "![Split](immagini/16_splitting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b0c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb6b714c",
   "metadata": {},
   "source": [
    "There are a lot of different types of splitters in Lang Chain, and we'll cover a few of them in this lesson. But, I would encourage you to check out the rest of them in your spare time. These text splitters vary across a bunch of dimensions. \n",
    "\n",
    "They can vary on how they split the chunks, what characters go into that. They can vary on how they measure the length of the chunks. Is it by characters? Is it by tokens? There are even some that use other smaller models to __determine when the end of a sentence might be and use that as a way of splitting chunks__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50586723",
   "metadata": {},
   "source": [
    "Another important part of splitting into chunks is also the __METADATA__.\n",
    "\n",
    "Maintaining the same metadata across all chunks, but also adding in new pieces of metadata when relevant, and so there are some text splitters that are really focused on that. \n",
    "\n",
    "The splitting of chunks can often be specific on the type of document that we're working with, and this is really apparent when you're splitting on code. So, we have a __language text splitter__ that has a bunch of different separators for a variety of different languages like Python, Ruby, C. And when splitting these documents, it takes those different languages and the relevant separators for those languages into account when it's doing the splitting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b356319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed73f1d",
   "metadata": {},
   "source": [
    "Next, we're going to import two of the most common types of text splitters in Lang Chain. \n",
    "\n",
    "### THE RECURSIVE CHARACTER TEXT SPLITTER & THE CHARACTER TEXT SPLITTER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d56523",
   "metadata": {},
   "source": [
    "We're going to first play around with a few toy use cases just to get a sense of what exactly these do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to set a relatively small chunk size of 26, \n",
    "# and an even smaller chunk overlap of 4, just so we can see what these can do.\n",
    "\n",
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93e8a9",
   "metadata": {},
   "source": [
    "Let's initialize these two different text splitters as *r_splitter* and *c_splitter*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4003eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca7fd8",
   "metadata": {},
   "source": [
    "Why doesn't this split the string below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the first string\n",
    "text1 = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31282eee",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "['abcdefghijklmnopqrstuvwxyz']\n",
    "```\n",
    "\n",
    "no need to even do any splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab210d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f180ed6a",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']\n",
    "```\n",
    "\n",
    "We can see starts with W, X, Y, Z. Those are the four CHUNK OVERLAPS, And then it continues with the rest of the string. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebec61f",
   "metadata": {},
   "source": [
    "Ok, this splits the string but we have an overlap specified as 5, but it looks like 3? (try an even number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d02164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaces between characters\n",
    "\n",
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096be63",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']\n",
    "```\n",
    "\n",
    "It's split into three chunks because there are spaces, so it takes up more space.\n",
    "\n",
    "That seems like only two characters but because of the space both in between the L and M, and then also, before the L and after the M that actually counts as the four that makes up the chunk overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53570532",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cbaa83",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "['a b c d e f g h i j k l m n o p q r s t u v w x y z']\n",
    "```\n",
    "\n",
    "The issue is the CHARACTER TEXT SPLITTER splits on a single character and by default that character is a newline character. But here, there are no newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  If we set the separator to be an empty space, we can see what happens then. Here it's split in the same way as before. \n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9cf1b",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e021d66",
   "metadata": {},
   "source": [
    "Try your own examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250432c0",
   "metadata": {},
   "source": [
    "## Recursive splitting details\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text. \n",
    "\n",
    "\\n\\n double newline symbol which is a typical separator between paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bc86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1a84c",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d11b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    # list of separators, and these are the default separators \n",
    "    # but we're just putting them in this notebook to better show what's going on.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fb4a6",
   "metadata": {},
   "source": [
    "What this mean is that when you're splitting a piece of text it will first try to split it by double newlines. And then, if it still needs to split the individual chunks more it will go on to single newlines. And then, if it still needs to do more it goes on to the space. And then, finally it will just go character by character if it really needs to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0298ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f236d6a",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
    " 'have a space.and words are separated by space.'] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e391d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00a81c",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
    " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa22a06",
   "metadata": {},
   "source": [
    "Let's reduce the chunk size a bit and add a period to our separators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a71ea",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related\",\n",
    " '. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
    " 'Paragraphs are often delimited with a carriage return or two carriage returns',\n",
    " '. Carriage returns are the \"backslash n\" you see embedded in this string',\n",
    " '. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n",
    "```\n",
    "If we run this text splitter, we can see that it's split on sentences, but the periods are actually in the wrong places. This is because of the regex that's going on underneath the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319cce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]  # split properly\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce1b29",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "```\n",
    "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related.\",\n",
    " 'For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
    " 'Paragraphs are often delimited with a carriage return or two carriage returns.',\n",
    " 'Carriage returns are the \"backslash n\" you see embedded in this string.',\n",
    " 'Sentences have a period at the end, but also, have a space.and words are separated by space.']\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc5268",
   "metadata": {},
   "source": [
    "## Real-world example with one of the PDFs that we worked with in the first document loading section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# define our text splitter \n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len   # using LEN, the Python built-in\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea38442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the split documents method\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268489e5",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9692439",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6df3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe6a709b",
   "metadata": {},
   "source": [
    "If we compare the length of those documents to the length of the original pages, we can see that there's been a bunch more documents that have been created as a result of this splitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecc5e0",
   "metadata": {},
   "source": [
    "## Notion_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "notion_db = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(notion_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b215810",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notion_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d2194",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23256ea3",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "353"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0d4e2",
   "metadata": {},
   "source": [
    "## Token splitting\n",
    "\n",
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in tokens.\n",
    "\n",
    "Tokens are often ~4 characters.\n",
    "\n",
    "The reason that this is useful is because often LLMs have context windows that are designated by token count. And so, it's important to know what the tokens are, and where they appear. And then, we can split on them to have a slightly more representative idea of how the LLM would view them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a94be9",
   "metadata": {},
   "source": [
    "To really get a sense for what the difference is between tokens and characters. \n",
    "Let's initialize the token text splitter with a chunk size of 1, and a chunk overlap of 0. So, this will split any text into a list of the relevant tokens. Let's create a fun made-up text, and when we split it, we can see that it's split into a bunch of different tokens, and they're all a little bit different in terms of their length and the number of characters in them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"foo bar bazzyfoo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a1298",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "```\n",
    "['foo', ' bar', ' b', 'az', 'zy', 'foo']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc72c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e337cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb01393",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "```\n",
    "Document(page_content='MachineLearning-Lecture01  \\n', metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb20876",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "```\n",
    "{'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}\n",
    "```\n",
    "\n",
    "This can contain information like where in the document, the chunk came from where it is relative to other things or concepts in the document and generally this information can be used when answering questions to provide more context about what this chunk is exactly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf268c38",
   "metadata": {},
   "source": [
    "## Context aware splitting\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below.\n",
    "\n",
    "This text splitter is the markdown header text splitter and what it will do is it will split a markdown file based on the header or any subheaders and then it will add those headers as content to the metadata fields and that will get passed on along to any chunks that originate from those splits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46498a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee892d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb33a2",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "```\n",
    "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3eace",
   "metadata": {},
   "source": [
    "*OUTPUT*\n",
    "\n",
    "```\n",
    "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda55ed",
   "metadata": {},
   "source": [
    "Try on a real Markdown file, like a Notion database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()\n",
    "txt = ' '.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40aba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits = markdown_splitter.split_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e74cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39021b8",
   "metadata": {},
   "source": [
    "*OUTPUT*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281c10a",
   "metadata": {},
   "source": [
    "```\n",
    "Document(page_content=\"This is a living document with everything we've learned working with people while running a startup. And, of course, we continue to learn. Therefore it's a document that will continue to change.  \\n**Everything related to working at Blendle and the people of Blendle, made public.**  \\nThese are the lessons from three years of working with the people of Blendle. It contains everything from [how our leaders lead](https://www.notion.so/ecfb7e647136468a9a0a32f1771a8f52?pvs=21) to [how we increase salaries](https://www.notion.so/Salary-Review-e11b6161c6d34f5c9568bb3e83ed96b6?pvs=21), from [how we hire](https://www.notion.so/Hiring-451bbcfe8d9b49438c0633326bb7af0a?pvs=21) and [fire](https://www.notion.so/Firing-5567687a2000496b8412e53cd58eed9d?pvs=21) to [how we think people should give each other feedback](https://www.notion.so/Our-Feedback-Process-eb64f1de796b4350aeab3bc068e3801f?pvs=21) â€” and much more.  \\nWe've made this document public because we want to learn from you. We're very much interested in your feedback (including weeding out typo's and Dunglish ;)). Email us at hr@blendle.com. If you're starting your own company or if you're curious as to how we do things at Blendle, we hope that our employee handbook inspires you.  \\nIf you want to work at Blendle you can check our [job ads here](https://blendle.homerun.co/). If you want to be kept in the loop about Blendle, you can sign up for [our behind the scenes newsletter](https://blendle.homerun.co/yes-keep-me-posted/tr/apply?token=8092d4128c306003d97dd3821bad06f2).\", metadata={'Header 1': \"Blendle's Employee Handbook\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc2285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
